{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "DeepImagePrior.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOXHcpZDYBF2",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/motykatomasz/DeepImagePrior/blob/master/DeepImagePrior.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PrJdFdwWU8ur",
        "colab_type": "text"
      },
      "source": [
        "Reproducing Deep Image Prior paper\n",
        "=====================\n",
        "\n",
        "In this notebook we reproduce Table 1 in Deep Image Prior paper. Although the authors of the paper made the code available online, this is out approach to independently reproduce thair results. \n",
        "We developed the code in Jupyter notebook and it is compatible with Google Colab platform to be used with GPU.\n",
        "\n",
        "\n",
        "## What is Deep Image Prior\n",
        "\n",
        "In the paper, the authors argue that a great\n",
        "deal of image statistics are captured by the structure of\n",
        "a convolutional image generator independent of learning.\n",
        "What it means is that we can train the generator netowrk on a single degraded image, instead of large dataset of example images,\n",
        "to reconstruct the image. In this scheme, the network weights serve\n",
        "as a parametrization of the restored image.\n",
        "\n",
        "\n",
        "## How does it work?\n",
        "\n",
        "Lets assume that our image x is under following process:\n",
        "\n",
        "$ x \\Rightarrow Degradation \\Rightarrow  \\hat{x} \\Rightarrow  Restoration \\Rightarrow x^{*} $\n",
        "\n",
        "Our goal is to find $ x^{*}$.\n",
        "We can do that by finding the MAP estimate of our posterior distribution of clean images:\n",
        "\n",
        "\\begin{equation}\n",
        "MAP: x^{*} = argmax_{x} p(x|\\hat{x})\n",
        "\\end{equation}\n",
        "\n",
        "As it is usually the case, obtaining posterior distribution $p(x|\\hat{x})$ is intractable. We can rewrite the equation using Bayes theorem:\n",
        "\n",
        "\\begin{equation}\n",
        "p(x|\\hat{x}) = \\frac{p(\\hat{x}|x)p(x)}{p(\\hat{x})} \\sim p(\\hat{x}|x)p(x)\n",
        "\\end{equation}\n",
        "\n",
        "\n",
        "to be continued...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pleuXuLEWBHr",
        "colab_type": "code",
        "outputId": "909c9cd5-3204-4cf5-d903-4bcc4d79591c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        }
      },
      "source": [
        "!pip3 install torch torchvision\n",
        "!apt-get update\n",
        "!apt-get install subversion\n",
        "!svn checkout https://github.com/DmitryUlyanov/deep-image-prior/trunk/data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Hit:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Hit:2 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:4 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "subversion is already the newest version (1.9.7-4ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 53 not upgraded.\n",
            "Checked out revision 55.\n",
            "Checked out revision 55.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJGTI8bsulQR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "6c9ad26b-1e97-4185-dda2-9bfae062ed3c"
      },
      "source": [
        "ls data/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdenoising\u001b[0m/          imagenet1000_clsid_to_human.txt  \u001b[01;34msr\u001b[0m/\n",
            "\u001b[01;34mfeature_inversion\u001b[0m/  \u001b[01;34minpainting\u001b[0m/                      teaser_compiled.jpg\n",
            "\u001b[01;34mflash_no_flash\u001b[0m/     \u001b[01;34mrestoration\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}