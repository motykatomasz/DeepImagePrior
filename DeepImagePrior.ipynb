{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "DeepImagePrior.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOXHcpZDYBF2"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/motykatomasz/DeepImagePrior/blob/master/DeepImagePrior.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PrJdFdwWU8ur",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Reproducing Deep Image Prior paper\n",
    "=====================\n",
    "\n",
    "In this notebook we reproduce Table 1 in Deep Image Prior paper. Although the authors of the paper made the code available online, this is out approach to independently reproduce thair results. \n",
    "We developed the code in Jupyter notebook and it is compatible with Google Colab platform to be used with GPU.\n",
    "\n",
    "\n",
    "## What is Deep Image Prior\n",
    "\n",
    "In the paper, the authors argue that a great\n",
    "deal of image statistics are captured by the structure of\n",
    "a convolutional image generator independent of learning.\n",
    "What it means is that we can train the generator netowrk on a single degraded image, instead of large dataset of example images,\n",
    "to reconstruct the image. In this scheme, the network weights serve\n",
    "as a parametrization of the restored image.\n",
    "\n",
    "\n",
    "## How does it work?\n",
    "\n",
    "Lets assume that our image x is under following process:\n",
    "\n",
    "$ x \\Rightarrow Degradation \\Rightarrow  \\hat{x} \\Rightarrow  Restoration \\Rightarrow x^{*} $\n",
    "\n",
    "Our goal is to find $ x^{*}$.\n",
    "We can do that by finding the MAP estimate of our posterior distribution of clean images:\n",
    "\n",
    "\\begin{equation}\n",
    "MAP: x^{*} = argmax_{x} p(x|\\hat{x})\n",
    "\\end{equation}\n",
    "\n",
    "As it is usually the case, obtaining posterior distribution $p(x|\\hat{x})$ is intractable. We can rewrite the equation using Bayes theorem:\n",
    "\n",
    "\\begin{equation}\n",
    "p(x|\\hat{x}) = \\frac{p(\\hat{x}|x)p(x)}{p(\\hat{x})} \\sim p(\\hat{x}|x)p(x)\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "to be continued...\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "pleuXuLEWBHr",
    "outputId": "820a1408-c684-4ad1-dda6-928a5f6bdfcf",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    }
   },
   "source": [
    "!pip install torch torchvision Pillow\n",
    "!apt-get update\n",
    "!apt-get install subversion\n",
    "!svn checkout https://github.com/DmitryUlyanov/deep-image-prior/trunk/data"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (1.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.18.2)\n",
      "Hit:1 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "Get:5 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
      "Ign:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Get:10 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "Get:11 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,784 kB]\n",
      "Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [832 kB]\n",
      "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [857 kB]\n",
      "Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,362 kB]\n",
      "Get:17 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [861 kB]\n",
      "Get:18 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,626 B]\n",
      "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [1,151 kB]\n",
      "Fetched 7,118 kB in 2s (3,462 kB/s)\n",
      "Reading package lists... Done\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  libapr1 libaprutil1 libserf-1-1 libsvn1\n",
      "Suggested packages:\n",
      "  db5.3-util libapache2-mod-svn subversion-tools\n",
      "The following NEW packages will be installed:\n",
      "  libapr1 libaprutil1 libserf-1-1 libsvn1 subversion\n",
      "0 upgraded, 5 newly installed, 0 to remove and 25 not upgraded.\n",
      "Need to get 2,237 kB of archives.\n",
      "After this operation, 9,910 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libapr1 amd64 1.6.3-2 [90.9 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 libaprutil1 amd64 1.6.1-2 [84.4 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libserf-1-1 amd64 1.3.9-6 [44.4 kB]\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libsvn1 amd64 1.9.7-4ubuntu1 [1,183 kB]\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic/universe amd64 subversion amd64 1.9.7-4ubuntu1 [834 kB]\n",
      "Fetched 2,237 kB in 1s (2,677 kB/s)\n",
      "Selecting previously unselected package libapr1:amd64.\n",
      "(Reading database ... 144542 files and directories currently installed.)\n",
      "Preparing to unpack .../libapr1_1.6.3-2_amd64.deb ...\n",
      "Unpacking libapr1:amd64 (1.6.3-2) ...\n",
      "Selecting previously unselected package libaprutil1:amd64.\n",
      "Preparing to unpack .../libaprutil1_1.6.1-2_amd64.deb ...\n",
      "Unpacking libaprutil1:amd64 (1.6.1-2) ...\n",
      "Selecting previously unselected package libserf-1-1:amd64.\n",
      "Preparing to unpack .../libserf-1-1_1.3.9-6_amd64.deb ...\n",
      "Unpacking libserf-1-1:amd64 (1.3.9-6) ...\n",
      "Selecting previously unselected package libsvn1:amd64.\n",
      "Preparing to unpack .../libsvn1_1.9.7-4ubuntu1_amd64.deb ...\n",
      "Unpacking libsvn1:amd64 (1.9.7-4ubuntu1) ...\n",
      "Selecting previously unselected package subversion.\n",
      "Preparing to unpack .../subversion_1.9.7-4ubuntu1_amd64.deb ...\n",
      "Unpacking subversion (1.9.7-4ubuntu1) ...\n",
      "Setting up libapr1:amd64 (1.6.3-2) ...\n",
      "Setting up libaprutil1:amd64 (1.6.1-2) ...\n",
      "Setting up libserf-1-1:amd64 (1.3.9-6) ...\n",
      "Setting up libsvn1:amd64 (1.9.7-4ubuntu1) ...\n",
      "Setting up subversion (1.9.7-4ubuntu1) ...\n",
      "Processing triggers for libc-bin (2.27-3ubuntu1) ...\n",
      "/sbin/ldconfig.real: /usr/local/lib/python3.6/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
      "\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "A    data/denoising\n",
      "A    data/denoising/F16_GT.png\n",
      "A    data/denoising/snail.jpg\n",
      "A    data/feature_inversion\n",
      "A    data/feature_inversion/building.jpg\n",
      "A    data/feature_inversion/monkey.jpg\n",
      "A    data/flash_no_flash\n",
      "A    data/flash_no_flash/cave01_00_flash.jpg\n",
      "A    data/flash_no_flash/cave01_01_noflash.jpg\n",
      "A    data/imagenet1000_clsid_to_human.txt\n",
      "A    data/inpainting\n",
      "A    data/inpainting/kate.png\n",
      "A    data/inpainting/kate_mask.png\n",
      "A    data/inpainting/library.png\n",
      "A    data/inpainting/library_mask.png\n",
      "A    data/inpainting/vase.png\n",
      "A    data/inpainting/vase_mask.png\n",
      "A    data/restoration\n",
      "A    data/restoration/barbara.png\n",
      "A    data/restoration/kate.png\n",
      "A    data/sr\n",
      "A    data/sr/zebra_GT.png\n",
      "A    data/sr/zebra_crop.png\n",
      "A    data/teaser_compiled.jpg\n",
      "Checked out revision 55.\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pI_ZTZRNQE1T",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "outputId": "148849c1-fd57-46a1-c808-b6c1f35a3758"
   },
   "source": [
    "try:\n",
    "    import models\n",
    "except ImportError:\n",
    "    from getpass import getpass\n",
    "    branch = input('branch (master): ')\n",
    "    branch = 'master' if branch == '' else branch\n",
    "    !pip install --ignore-installed git+https://{input('git user: ')}:{getpass('git password: ')}@github.com/motykatomasz/DeepImagePrior@{branch}"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "branch (master): andrea\n",
      "git user: andful\n",
      "git password: ··········\n",
      "Collecting git+https://andful:****@github.com/motykatomasz/DeepImagePrior@andrea\n",
      "  Cloning https://andful:****@github.com/motykatomasz/DeepImagePrior (to revision andrea) to /tmp/pip-req-build-cra2m41m\n",
      "  Running command git clone -q 'https://andful:****@github.com/motykatomasz/DeepImagePrior' /tmp/pip-req-build-cra2m41m\n",
      "  Running command git checkout -b andrea --track origin/andrea\n",
      "  Switched to a new branch 'andrea'\n",
      "  Branch 'andrea' set up to track remote branch 'andrea' from 'origin'.\n",
      "Building wheels for collected packages: Deep-Image-Prior\n",
      "  Building wheel for Deep-Image-Prior (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for Deep-Image-Prior: filename=Deep_Image_Prior-0.0.1-cp36-none-any.whl size=4186 sha256=707415969b4e06e53c1a78a182f90d248ec5c1f26b4558fc23918bca6c896332\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-5t10p9t8/wheels/22/9a/86/6ec265e9bc8db28f9d764bd0a0d6f258faf4c4f0529a1a3512\n",
      "Successfully built Deep-Image-Prior\n",
      "Installing collected packages: Deep-Image-Prior\n",
      "Successfully installed Deep-Image-Prior-0.0.1\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "models"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     }
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "rhiwfEmO0EeJ",
    "colab": {},
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "from models.unet import UNet\n",
    "import torch.optim as optim\n",
    "from models.utils import z, imshow, image_to_tensor, tensor_to_image\n",
    "from models.configs import inpaintingSettings"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[1;31m# noqa F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorboard'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-befcf6db7ca7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./runs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\tensorboard\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[1;31m# noqa F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     raise ImportError('TensorBoard logging requires TensorBoard with Python summary writer installed. '\n\u001b[0m\u001b[0;32m      5\u001b[0m                       'This should be available in 1.14 or above.')\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[1;31m# noqa F401\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above."
     ],
     "ename": "ImportError",
     "evalue": "TensorBoard logging requires TensorBoard with Python summary writer installed. This should be available in 1.14 or above.",
     "output_type": "error"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('./runs')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab_type": "code",
    "id": "w7rpLisz0H9h",
    "outputId": "31d6aee7-28e7-4076-81d3-737b0088196a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "source": [
    "img_path = \"data/inpainting/kate.png\"\n",
    "img = Image.open(img_path)\n",
    "imshow(asarray(img))\n",
    "\n",
    "mask_path = \"data/inpainting/kate_mask.png\"\n",
    "mask = Image.open(mask_path)\n",
    "imshow(asarray(mask))\n",
    "\n",
    "x = image_to_tensor(img)\n",
    "mask = image_to_tensor(mask)\n",
    "\n",
    "net = UNet(inpaintingSettings)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "mse = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# Num of iters for training\n",
    "num_iters = 5000\n",
    "\n",
    "# Num of iters when to save image\n",
    "save_frequency = 250\n",
    "\n",
    "#Since we only have 1 image to train on, we set zero_gradienet once at the beginning\n",
    "optimizer.zero_grad()\n",
    "\n",
    "z0 = z(shape=(img.height, img.width), channels=32)\n",
    "\n",
    "for i in range(num_iters):\n",
    "    output = net(z0)\n",
    "\n",
    "    # Optimizer\n",
    "    loss = torch.sum(torch.mul((output - x), mask)**2)\n",
    "    # loss = mse(output * mask, x * mask)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    writer.add_scalar('Train/loss',loss.item(),i)\n",
    "    \n",
    "    if i % save_frequency == 0:\n",
    "        print('Step :{}, Loss: {}'.format(i, loss.data.cpu()))\n",
    "        out_img = tensor_to_image(output)\n",
    "        imshow(asarray(out_img))\n",
    "        print('OUTPUT IMAGE')\n",
    "    \n",
    "    writer.close()\n",
    "        \n",
    "%tensorboard --logdir=runs"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-0f1e782c72a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/inpainting/kate.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmask_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"data/inpainting/kate_mask.png\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode)\u001b[0m\n\u001b[0;32m   2807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2808\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2809\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2810\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2811\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/inpainting/kate.png'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/inpainting/kate.png'",
     "output_type": "error"
    }
   ]
  }
 ]
}